Building English Language Models and Counts...
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/iwslt2014zh-en/train/train.token.clean.50.en
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 3177529 types 52154
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:625848 2:2914181888 3:5464091136
Statistics:
1 52154 D1=0.600291 D2=1.01491 D3+=1.51906
2 612598 D1=0.736423 D2=1.09597 D3+=1.41654
3 1617414 D1=0.824151 D2=1.15144 D3+=1.38724
Memory estimate for binary LM:
type       kB
probing 44113 assuming -p 1.5
probing 47906 assuming -r models -p 1.5
trie    17980 without quantization
trie     9927 assuming -q 8 -b 8 quantization 
trie    17031 assuming -a 22 array pointer compression
trie     8979 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:625848 2:9801568 3:32348280
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
----------------------------------------------------------------------------------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++****************************************************************************************************####################################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:625848 2:9801568 3:32348280
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
----------------------------------------------------------------------------------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++****************************************************************************************************####################################################################################################
=== 5/5 Writing ARPA model ===
Name:lmplz	VmPeak:8349368 kB	VmRSS:46424 kB	RSSMax:1947420 kB	user:2.77132	sys:0.718042	CPU:3.48936	real:3.11453
Building Chinese Language Models and Counts...
=== 1/5 Counting and sorting n-grams ===
Reading /mnt/iwslt2014zh-en/train/train.token.clean.50.zh
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Unigram tokens 2996077 types 53426
=== 2/5 Calculating and sorting adjusted counts ===
Chain sizes: 1:641112 2:2914176512 3:5464080896
Statistics:
1 53426 D1=0.600043 D2=1.01491 D3+=1.45905
2 798149 D1=0.751852 D2=1.11112 D3+=1.3772
3 1918943 D1=0.853443 D2=1.1842 D3+=1.40828
Memory estimate for binary LM:
type    MB
probing 52 assuming -p 1.5
probing 57 assuming -r models -p 1.5
trie    21 without quantization
trie    11 assuming -q 8 -b 8 quantization 
trie    20 assuming -a 22 array pointer compression
trie    10 assuming -a 22 -q 8 -b 8 array pointer compression and quantization
=== 3/5 Calculating and sorting initial probabilities ===
Chain sizes: 1:641112 2:12770384 3:38378860
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
----------------------------------------------------------------------------------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++****************************************************************************************************####################################################################################################
=== 4/5 Calculating and writing order-interpolated probabilities ===
Chain sizes: 1:641112 2:12770384 3:38378860
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
----------------------------------------------------------------------------------------------------++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++****************************************************************************************************####################################################################################################
=== 5/5 Writing ARPA model ===
Name:lmplz	VmPeak:8341172 kB	VmRSS:18072 kB	RSSMax:1952764 kB	user:3.19992	sys:0.838668	CPU:4.03858	real:3.47702
Building binary English language models...
Reading /mnt/iwslt2014zh-en/train/train.token.clean.50.lm.en
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
SUCCESS
Building binary Chinese language models...
Reading /mnt/iwslt2014zh-en/train/train.token.clean.50.lm.zh
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
SUCCESS
is=18 2 -2.6965108	this=45 3 -0.84844	an=281 3 -2.317651	English=0 1 -6.3741117	sentence=6235 1 -4.3026004	?=54 2 -2.2268012	</s>=2 3 -0.21853548	Total: -18.984652 OOV: 1
Perplexity including OOVs:	515.3390835409365
Perplexity excluding OOVs:	126.40278774929547
OOVs:	1
Tokens:	7
Name:query	VmPeak:62996 kB	VmRSS:3496 kB	RSSMax:47488 kB	user:0	sys:0.01028	CPU:0.01028	real:0.00932803
这=53 2 -1.1756101	是=4 3 -0.37456116	中文=18412 3 -4.4705014	吗?=0 1 -6.251103	</s>=2 1 -1.8725955	Total: -14.144372 OOV: 1
Perplexity including OOVs:	674.3329750094292
Perplexity excluding OOVs:	94.04100582341326
OOVs:	1
Tokens:	5
Name:query	VmPeak:72676 kB	VmRSS:3672 kB	RSSMax:57344 kB	user:0	sys:0.010803	CPU:0.010803	real:0.00973144
